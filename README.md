<p align="center">
<img src="https://github.com/izamith/signos/blob/7ae0ee972bbc564c37dd97abcf4616816fd24b21/assets/Framelogo.png" alt="signos" width="300">
<h3 align="center">Usando machine learning para reconhecer sinais de libras</h3>
</p>
<p align="center">"Libras √© a sigla da L√≠ngua Brasileira de Sinais, uma l√≠ngua de modalidade gestual-visual onde √© poss√≠vel se comunicar atrav√©s de gestos, express√µes faciais e corporais. √â considerada uma l√≠ngua oficial do Brasil desde 24 de Abril de 2002." <i>(<a href="https://libras.com">Libras.com</a>)</i></p>

signos √© um projeto com a ml5: biblioteca de machine learning que te permite criar uma rede neural e treinar essa rede direto no navegador! üåê

A ml5 tem v√°rios modelos pr√©-treinados como um classificador de imagens, poses de um corpo e posi√ß√µes de m√£os e dedos. Pra fazer esse projeto eu usei o terceiro, que se chama HandPose. üôã‚Äç‚ôÄÔ∏è

O HandPose me ajudou a identificar o que √© uma m√£o, o que s√£o dedos e onde est√£o esses elementos no v√≠deo. 


![Alt Text](https://media.giphy.com/media/UiWilQulmHXeLcnWhT/giphy.gif)</br></br>


Depois, eu treinei minha pr√≥pria rede neural para identificar posi√ß√µes de dedos e m√£os e o que cada uma delas significa.

![Alt Text](https://media.giphy.com/media/VEQmZ487UX2VGqyiW7/giphy.gif)


No final, o sistema foi treinado para reconhecer os sinais "Oi", "D√∫vida" e "Entendi". Esses sinais foram registrados de acordo com o[ dicion√°rio de libras (CEAD) ](https://sistemas.cead.ufv.br/capes/dicionario/)

![Alt Text](https://media.giphy.com/media/EQQQDezl9W9URXICDV/giphy.gif)

<a href="https://izamith.github.io/signos/">ACESSE!</a></br></br></br></br>


### Tecnologias
* <a href="https://ml5js.org">ml5.js</a>
* <a href="https://learn.ml5js.org/#/reference/handpose">HandPose</a>
* <a href="https://p5js.org">p5.js</a>

### Refer√™ncias
* <a href="https://www.youtube.com/channel/UCBMCoXdeIq_NP6ihSh0RI_w">Canal - Sinais di√°rios em libras</a>
* <a href="https://www.youtube.com/watch?v=9z9mbiOZqSs&t=922s">Coding Challenge #157: Zoom Annotations with Machine Learning + p5.js</a>
* <a href="https://www.youtube.com/watch?v=FYgYyq-xqAw&t=1384s">ml5.js: Pose Classification with PoseNet and ml5.neuralNetwork()</a>
